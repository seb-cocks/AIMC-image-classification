{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18fee19",
   "metadata": {},
   "source": [
    "# ViT / VViT Transformer Models ‚Äî Phase-Spectrum Based Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7783d1",
   "metadata": {},
   "source": [
    "### Reference\n",
    "This notebook implements the transformer-based automatic modulation recognition models presented by  \n",
    "**Bhatti, Sidra Ghayour; Taj, Imtiaz Ahmad; Ullah, Mohsin; and Bhatti, Aamer Iqbal (2024)** ‚Äî  \n",
    "*‚ÄúTransformer-Based Models for Intrapulse Modulation Recognition of Radar Waveforms.‚Äù*  \n",
    "*Engineering Applications of Artificial Intelligence*, **136**, 108989.  \n",
    "**BibTeX:** [@RN181]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaaa649",
   "metadata": {},
   "source": [
    "### 1 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e253867",
   "metadata": {},
   "source": [
    "#### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097615ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import gc\n",
    "import h5py\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from ViT import MainModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2bf590",
   "metadata": {},
   "source": [
    "#### 1.2 Device Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device Selection\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a330b80",
   "metadata": {},
   "source": [
    "#### 1.3 Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45330c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "def load_algorithm_snr_h5s(root_folder, mod_types):\n",
    "    \"\"\"\n",
    "    Loads .h5 spectrogram files from a specific algorithm's snr_X folder,\n",
    "    filtered by modulation type (FM, PM, HYBRID).\n",
    "\n",
    "    Parameters:\n",
    "    - root_folder (str): Path to the snr_X directory (e.g., .../preprocessed_images/vit/snr_0)\n",
    "    - mod_types (list): List of modulation categories to include, e.g., ['FM', 'PM']\n",
    "\n",
    "    Returns:\n",
    "    - X: np.ndarray of images\n",
    "    - y: np.ndarray of labels (modulation names as strings)\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for mod_type in mod_types:\n",
    "        mod_path = os.path.join(root_folder, mod_type)\n",
    "        if not os.path.exists(mod_path):\n",
    "            print(f\"‚ö†Ô∏è Warning: {mod_path} does not exist. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"üìÇ Loading from {mod_type}...\")\n",
    "        files = [f for f in os.listdir(mod_path) if f.endswith(\".h5\")]\n",
    "\n",
    "        for file in tqdm(files, desc=f\"   {mod_type}\", unit=\"file\"):\n",
    "            mod_name = file[:-3]  # Strip '.h5'\n",
    "            file_path = os.path.join(mod_path, file)\n",
    "\n",
    "            try:\n",
    "                with h5py.File(file_path, \"r\") as h5f:\n",
    "                    if mod_name not in h5f:\n",
    "                        print(f\"‚ö†Ô∏è Warning: No top-level group named '{mod_name}' in {file_path}\")\n",
    "                        continue\n",
    "                    group = h5f[mod_name]\n",
    "                    for key in group.keys():\n",
    "                        img = np.array(group[key])\n",
    "                        X.append(img)\n",
    "                        y.append(mod_name)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to load {file_path}: {e}\")\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    # Cleanup after loading\n",
    "    gc.collect()\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296179d0",
   "metadata": {},
   "source": [
    "#### 1.4 Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8712ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "def prepare_dataloader(X, y, batch_size=32, shuffle=False, num_workers=2):\n",
    "    \"\"\"\n",
    "    Prepares a DataLoader from X and y, keeping data on CPU until batches are moved to GPU.\n",
    "\n",
    "    Parameters:\n",
    "    - X: np.ndarray or torch.Tensor of input data\n",
    "    - y: np.ndarray or torch.Tensor of labels\n",
    "    - batch_size: int, size of each batch\n",
    "    - shuffle: bool, whether to shuffle the data\n",
    "    - num_workers: int, number of workers for loading data\n",
    "\n",
    "    Returns:\n",
    "    - DataLoader object\n",
    "    \"\"\"\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = torch.tensor(X, dtype=torch.uint8)\n",
    "    elif not isinstance(X, torch.Tensor):\n",
    "        raise TypeError(\"Input X must be a NumPy array or PyTorch tensor\")\n",
    "\n",
    "    if isinstance(y, np.ndarray):\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "    elif not isinstance(y, torch.Tensor):\n",
    "        raise TypeError(\"Labels y must be a NumPy array or PyTorch tensor\")\n",
    "\n",
    "    # Ensure X has four dimensions (N, C, H, W)\n",
    "    if X.ndim == 3:  # If (N, H, W), add a channel dimension\n",
    "        X = X.unsqueeze(1)  # (N, 1, H, W)\n",
    "    elif X.ndim == 4 and X.shape[-1] in [1, 3]:  # (N, H, W, C) case\n",
    "        X = X.permute(0, 3, 1, 2)  # Convert to (N, C, H, W)\n",
    "\n",
    "    dataset = TensorDataset(X, y)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    # Cleanup after creating DataLoader\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272dd1a",
   "metadata": {},
   "source": [
    "### 2 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303abbb0",
   "metadata": {},
   "source": [
    "#### 2.1 Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061cefa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    device,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler=None,\n",
    "    epochs=10,\n",
    "    patience=3,\n",
    "    min_delta=0.0,\n",
    "    model_save_path=None\n",
    "):\n",
    "    model.to(device)\n",
    "    best_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True, dynamic_ncols=True)\n",
    "\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = inputs.float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "            # Cleanup after each batch\n",
    "            # del inputs, labels, outputs, loss\n",
    "            # gc.collect()\n",
    "            # if torch.cuda.is_available():\n",
    "            #     torch.cuda.empty_cache()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        loss_history.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1} average loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Save best model\n",
    "        if avg_loss < best_loss - min_delta:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "            if model_save_path:\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    # Final cleanup after training\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ab01f",
   "metadata": {},
   "source": [
    "##### 2.1.1 Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss Curve\n",
    "def plot_loss_curve(loss_history, output_path, title=\"Training Loss Over Epochs\"):\n",
    "    epochs = len(loss_history)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, epochs + 1), loss_history, marker=\"o\", label=\"Training Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(output_path + \"loss_curve.png\")\n",
    "    plt.close()\n",
    "    # Cleanup after plotting\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa9cfc",
   "metadata": {},
   "source": [
    "##### 2.1.2 Conf Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7866d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Display\n",
    "def display_confusion_matrix(\n",
    "    model, data_loader, device, output_path, class_names=None, title=\"Confusion Matrix\"\n",
    "):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output_class = model(inputs)\n",
    "            preds = torch.argmax(output_class, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            # Cleanup after each batch\n",
    "            del inputs, labels, output_class, preds\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    num_classes = cm.shape[0]\n",
    "    cm_normalized = cm.astype(np.float32) / cm.sum(axis=1, keepdims=True) * 100\n",
    "\n",
    "    if class_names is None:\n",
    "        class_names = [str(i) for i in range(num_classes)]\n",
    "\n",
    "    plt.figure(figsize=(max(10, num_classes * 0.8), max(8, num_classes * 0.6)))\n",
    "    im = plt.imshow(cm_normalized, interpolation=\"nearest\", cmap=\"Blues\")\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.colorbar(im, label=\"Percentage\")\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, class_names, rotation=45, ha=\"right\", va=\"top\", fontsize=max(8, 12 - num_classes // 5))\n",
    "    plt.yticks(tick_marks, class_names, fontsize=max(8, 12 - num_classes // 5))\n",
    "\n",
    "    thresh = cm_normalized.max() / 2.0\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            plt.text(\n",
    "                j, i, f\"{cm_normalized[i, j]:.1f}\",\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_normalized[i, j] > thresh else \"black\",\n",
    "                fontsize=max(8, 12 - num_classes // 5),\n",
    "            )\n",
    "\n",
    "    plt.ylabel(\"True Label\", fontsize=12, labelpad=10)\n",
    "    plt.xlabel(\"Predicted Label\", fontsize=12, labelpad=10)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2 + num_classes * 0.005)\n",
    "    plt.savefig(output_path + \"conf_matrix.png\")\n",
    "    plt.close()\n",
    "    # Cleanup after plotting\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077949a0",
   "metadata": {},
   "source": [
    "### 3 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea4c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "def evaluate_model(model, test_loader, label_encoder, device, output_path):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = inputs.float()\n",
    "            output_class = model(inputs)\n",
    "            preds = torch.argmax(output_class, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            y_true.extend(labels.cpu().tolist())\n",
    "            y_pred.extend(preds.cpu().tolist())\n",
    "            # Cleanup after each batch\n",
    "            del inputs, labels, output_class, preds\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    class_names = label_encoder.classes_\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype(np.float32) / cm.sum(axis=1, keepdims=True) * 100\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(max(10, num_classes * 0.8), max(8, num_classes * 0.6)))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=class_names)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".1f\", ax=ax)\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha=\"right\", va=\"top\", fontsize=max(8, 12 - num_classes // 5))\n",
    "    ax.set_yticklabels(class_names, rotation=0, fontsize=max(8, 12 - num_classes // 5))\n",
    "    ax.set_xlabel(\"Predicted Label\", fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel(\"True Label\", fontsize=12, labelpad=10)\n",
    "    ax.set_title(\"Confusion Matrix (Percentage)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2 + num_classes * 0.005)\n",
    "    plt.savefig(output_path + \"test_conf_matrix.png\")\n",
    "    plt.close()\n",
    "    # Cleanup after plotting\n",
    "    gc.collect()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159d6b8c",
   "metadata": {},
   "source": [
    "### 4 Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Execution\n",
    "data_path = \"C:\\\\Apps\\\\Code\\\\aimc-spec-7\\\\preprocessed_images\\\\vit\\\\\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "output_path = \"C:\\\\Apps\\\\Code\\\\ViT\\\\\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "snr_range = [10, 5, 0, -2, -4, -6, -8, -10, -12, -14, -16, -18, -20]\n",
    "# snr_range = [10]\n",
    "\n",
    "mod_types = [\n",
    "    \"FM\",\n",
    "    # \"PM\",\n",
    "    # \"HYBRID\",\n",
    "]\n",
    "input_parameters = {\n",
    "    \"epoch_count\": 200,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"csv\": \"vit\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5732653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect training and testing data from all SNRs\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "test_data_by_snr = {}\n",
    "\n",
    "for snr in snr_range:\n",
    "    input_data_folder = data_path + f\"snr_{snr}\"\n",
    "    print(f\"Loading {input_data_folder}\")\n",
    "    X, y = load_algorithm_snr_h5s(input_data_folder, mod_types)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    X_train_list.append(X_train)\n",
    "    y_train_list.append(y_train)\n",
    "    test_data_by_snr[snr] = (X_test, y_test)\n",
    "    # Cleanup after splitting\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "\n",
    "# Combine training data\n",
    "print(f\"Combining training data\")    \n",
    "X_train_all = np.concatenate(X_train_list, axis=0)\n",
    "y_train_all = np.concatenate(y_train_list, axis=0)\n",
    "# Cleanup after concatenation\n",
    "del X_train_list, y_train_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb337b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_all_encoded = label_encoder.fit_transform(y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save label encoder\n",
    "mds = \"ALL\" if len(mod_types) == 3 else mod_types[0]\n",
    "output_data_folder = output_path + f\"snr_all_mds_{mds}_e{input_parameters['epoch_count']}_lr{input_parameters['learning_rate']}\\\\\"\n",
    "os.makedirs(output_data_folder, exist_ok=True)\n",
    "joblib.dump(label_encoder, output_data_folder + \"label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ec600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training DataLoader\n",
    "train_loader = prepare_dataloader(\n",
    "    X_train_all,\n",
    "    y_train_all_encoded,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# Cleanup after creating DataLoader\n",
    "del X_train_all, y_train_all, y_train_all_encoded\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a117b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = MainModel(\n",
    "    num_classes=len(label_encoder.classes_),\n",
    "    image_size=(184, 276),\n",
    "    patch_size=23,\n",
    "    dim=64,\n",
    "    depth=8,\n",
    "    heads=4,\n",
    "    mlp_dims=(2048, 1024)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=input_parameters[\"learning_rate\"])\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=45, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df33cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# print(f\"train\")\n",
    "start_time = time.time()\n",
    "loss_history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    epochs=input_parameters[\"epoch_count\"],\n",
    "    patience=50,\n",
    "    model_save_path=output_data_folder + \"best_model.pth\"\n",
    ")\n",
    "time_taken = time.time() - start_time\n",
    "\n",
    "# Save loss history and plot\n",
    "np.savetxt(output_data_folder + \"loss_history.csv\", loss_history, delimiter=\",\")\n",
    "plot_loss_curve(loss_history, output_data_folder)\n",
    "display_confusion_matrix(model, train_loader, device, output_data_folder)\n",
    "\n",
    "# Evaluate on each SNR's test set\n",
    "results = []\n",
    "for snr in snr_range:\n",
    "    X_test, y_test = test_data_by_snr[snr]\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "    test_loader = prepare_dataloader(\n",
    "        X_test,\n",
    "        y_test_encoded,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "    )\n",
    "    acc = evaluate_model(model, test_loader, label_encoder, device, output_data_folder + f\"snr_{snr}_\")\n",
    "    results.append({\n",
    "        \"Algorithm\": \"ViT\",\n",
    "        \"SNR\": snr,\n",
    "        \"Modulations\": mds,\n",
    "        \"Accuracy (%)\": acc,\n",
    "        \"Time Taken (Minutes)\": round(time_taken / 60, 2),\n",
    "        \"Learning Rate\": input_parameters[\"learning_rate\"],\n",
    "        \"Epoch Count\": f\"{200} / {input_parameters['epoch_count']}\"\n",
    "    })\n",
    "    # Cleanup after evaluation\n",
    "    del X_test, y_test, y_test_encoded, test_loader\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Cleanup after loop\n",
    "del test_data_by_snr\n",
    "gc.collect()\n",
    "\n",
    "# Save results to CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(output_data_folder + \"test_results.csv\", index=False)\n",
    "# Final cleanup\n",
    "del model, criterion, optimizer, scheduler, label_encoder, results, df\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa492499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final cleanup after execution\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
