{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Improved LPI Radar Waveform Recognition Framework With LDC-Unet and SSR-Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "import joblib\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchinfo import summary\n",
    "\n",
    "from LDC_Unet import MainModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Device Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_algorithm_snr_h5s(root_folder, mod_types):\n",
    "    \"\"\"\n",
    "    Loads .h5 spectrogram files from a specific algorithm's snr_X folder,\n",
    "    filtered by modulation type (FM, PM, HYBRID).\n",
    "\n",
    "    Parameters:\n",
    "    - root_folder (str): Path to the snr_X directory (e.g., .../preprocessed_images/cdae/snr_0)\n",
    "    - mod_types (list): List of modulation categories to include, e.g., ['FM', 'PM']\n",
    "\n",
    "    Returns:\n",
    "    - X: np.ndarray of images\n",
    "    - y: np.ndarray of labels (modulation names as strings)\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for mod_type in mod_types:\n",
    "        mod_path = os.path.join(root_folder, mod_type)\n",
    "        if not os.path.exists(mod_path):\n",
    "            print(f\"‚ö†Ô∏è Warning: {mod_path} does not exist. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"üìÇ Loading from {mod_type}...\")\n",
    "        files = [f for f in os.listdir(mod_path) if f.endswith(\".h5\")]\n",
    "\n",
    "        for file in tqdm(files, desc=f\"   {mod_type}\", unit=\"file\"):\n",
    "            mod_name = file[:-3]  # Strip '.h5'\n",
    "            file_path = os.path.join(mod_path, file)\n",
    "\n",
    "            try:\n",
    "                with h5py.File(file_path, \"r\") as h5f:\n",
    "                    if mod_name not in h5f:\n",
    "                        print(f\"‚ö†Ô∏è Warning: No top-level group named '{mod_name}' in {file_path}\")\n",
    "                        continue\n",
    "                    group = h5f[mod_name]\n",
    "                    for key in group.keys():\n",
    "                        img = np.array(group[key])\n",
    "                        X.append(img)\n",
    "                        y.append(mod_name)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to load {file_path}: {e}\")\n",
    "\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(X, y, batch_size=32, shuffle=False, num_workers=0, device=\"cpu\"):\n",
    "    # Convert NumPy arrays to PyTorch tensors\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "    elif not isinstance(X, torch.Tensor):\n",
    "        raise TypeError(\"Input X must be a NumPy array or PyTorch tensor\")\n",
    "\n",
    "    if isinstance(y, np.ndarray):\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "    elif not isinstance(y, torch.Tensor):\n",
    "        raise TypeError(\"Labels y must be a NumPy array or PyTorch tensor\")\n",
    "\n",
    "    # Ensure X has shape (N, C, H, W)\n",
    "    if X.ndim == 3:\n",
    "        X = X.unsqueeze(1)\n",
    "    elif X.ndim == 4 and X.shape[-1] in [1, 3]:\n",
    "        X = X.permute(0, 3, 1, 2)\n",
    "\n",
    "    dataset = TensorDataset(X, y)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=(device == \"cuda\"),\n",
    "    )\n",
    "\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSRLoss(nn.Module):\n",
    "    def __init__(self, num_classes, feature_dim, lambda_reg=0.12):\n",
    "        super(SSRLoss, self).__init__()\n",
    "        self.lambda_reg = lambda_reg  # Weight factor for L1 loss\n",
    "        self.num_classes = num_classes\n",
    "        self.feature_dim = feature_dim\n",
    "        self.centers = nn.Parameter(torch.randn(num_classes, feature_dim))  # Learnable class centers\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, features, labels, logits):\n",
    "        \"\"\"\n",
    "        :param features: Feature vectors before FC layer (batch_size, feature_dim)\n",
    "        :param labels: Class labels (batch_size,)\n",
    "        :param logits: Output logits before softmax (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        # Compute softmax loss\n",
    "        loss_softmax = self.cross_entropy(logits, labels)\n",
    "\n",
    "        # Get the class centers for each sample\n",
    "        centers_batch = self.centers[labels]  # Shape: (batch_size, feature_dim)\n",
    "\n",
    "        # Compute self-regularization loss (L1 distance)\n",
    "        loss_reg = torch.mean(torch.abs(features - centers_batch))\n",
    "\n",
    "        # Final SSR-Loss\n",
    "        loss = loss_softmax + self.lambda_reg * loss_reg\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    device,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler=None,\n",
    "    epochs=10,\n",
    "    patience=3,\n",
    "    min_delta=0.0,\n",
    "    output_model_dir=\"models\",\n",
    "    save_every=5,\n",
    "    start_epoch=0\n",
    "):\n",
    "    os.makedirs(output_model_dir, exist_ok=True)\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    loss_history = []\n",
    "    best_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    def cleanup_old_models():\n",
    "        model_files = glob.glob(os.path.join(output_model_dir, \"epoch_*.pth\"))\n",
    "        model_files_with_epoch = []\n",
    "        for f in model_files:\n",
    "            match = re.search(r\"epoch_(\\d+)_\", os.path.basename(f))\n",
    "            if match:\n",
    "                model_files_with_epoch.append((int(match.group(1)), f))\n",
    "        model_files_with_epoch.sort(reverse=True)\n",
    "        for _, old_file in model_files_with_epoch[3:]:\n",
    "            try:\n",
    "                os.remove(old_file)\n",
    "                print(f\"üóëÔ∏è Deleted old model: {old_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error deleting {old_file}: {e}\")\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        total_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True, dynamic_ncols=True)\n",
    "\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            features, logits = model(inputs)\n",
    "            loss = criterion(features, labels, logits)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        loss_history.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1} average loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        improved = avg_loss < best_loss - min_delta\n",
    "        if improved or (epoch + 1) % save_every == 0:\n",
    "            if improved:\n",
    "                best_loss = avg_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "            model_cpu = model.to('cpu')\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model_cpu.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                'loss': avg_loss,\n",
    "                'args': {\n",
    "                    'batch_size': train_loader.batch_size,\n",
    "                    'timestamp': time.time()\n",
    "                },\n",
    "                'random_state': {\n",
    "                    'torch': torch.get_rng_state(),\n",
    "                    'cuda': torch.cuda.get_rng_state_all() if torch.cuda.is_available() else None,\n",
    "                    'numpy': np.random.get_state(),\n",
    "                    'python': random.getstate()\n",
    "                }\n",
    "            }\n",
    "\n",
    "            save_path = os.path.join(output_model_dir, f\"epoch_{epoch+1}_loss_{avg_loss:.4f}.pth\")\n",
    "            torch.save(checkpoint, save_path)\n",
    "            print(f\"‚úÖ Full checkpoint saved at epoch {epoch+1} to {save_path}\")\n",
    "\n",
    "            model.to(device)\n",
    "            model.train()\n",
    "\n",
    "            cleanup_old_models()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    return loss_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(loss_history, output_path, title=\"Training Loss Over Epochs\"):\n",
    "    epochs = len(loss_history)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, epochs + 1), loss_history, marker=\"o\", label=\"Training Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(output_path + f\"loss_curve.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conf Matirx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_confusion_matrix(\n",
    "    model, data_loader, device, output_path, class_names=None, title=\"Confusion Matrix\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate and display a normalized confusion matrix for a trained model.\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): Trained PyTorch model.\n",
    "        data_loader (torch.utils.data.DataLoader): DataLoader for evaluation dataset.\n",
    "        device (torch.device): Device to run evaluation on (CPU/GPU).\n",
    "        class_names (list, optional): List of class names. If None, uses numeric indices.\n",
    "        title (str): Title of the confusion matrix plot.\n",
    "    \"\"\"\n",
    "    # Switch model to evaluation mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Disable gradient calculations for inference\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass: Ignore output_image, focus only on output_class\n",
    "            _, output_class = model(inputs)\n",
    "\n",
    "            # Get predicted class labels\n",
    "            preds = torch.argmax(output_class, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    num_classes = cm.shape[0]\n",
    "    \n",
    "    # Normalize confusion matrix to percentages\n",
    "    cm_normalized = cm.astype(np.float32) / cm.sum(axis=1, keepdims=True) * 100\n",
    "\n",
    "    # If class_names isn't provided, use numeric class indices\n",
    "    if class_names is None:\n",
    "        class_names = [str(i) for i in range(num_classes)]\n",
    "\n",
    "    # Plotting the confusion matrix\n",
    "    plt.figure(figsize=(max(10, num_classes * 0.8), max(8, num_classes * 0.6)))  # Dynamic size\n",
    "    im = plt.imshow(cm_normalized, interpolation=\"nearest\", cmap=\"Blues\")\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.colorbar(im, label=\"Percentage\")  # Add colorbar with label\n",
    "\n",
    "    # Create tick marks for class labels\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, class_names, rotation=45, ha=\"right\", va=\"top\", fontsize=max(8, 12 - num_classes // 5))\n",
    "    plt.yticks(tick_marks, class_names, fontsize=max(8, 12 - num_classes // 5))\n",
    "\n",
    "    # Annotate the matrix cells with percentage values\n",
    "    thresh = cm_normalized.max() / 2.0\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            plt.text(\n",
    "                j,\n",
    "                i,\n",
    "                f\"{cm_normalized[i, j]:.1f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"white\" if cm_normalized[i, j] > thresh else \"black\",\n",
    "                fontsize=max(8, 12 - num_classes // 5),\n",
    "            )\n",
    "\n",
    "    plt.ylabel(\"True Label\", fontsize=12, labelpad=10)\n",
    "    plt.xlabel(\"Predicted Label\", fontsize=12, labelpad=10)\n",
    "    \n",
    "    # Adjust layout with extra bottom margin for rotated labels\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2 + num_classes * 0.005)  # Dynamic bottom margin\n",
    "    \n",
    "    plt.savefig(output_path + f\"conf_matrix.png\")\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, label_encoder, device, output_path, snr):\n",
    "    \"\"\"\n",
    "    Evaluates the trained model and displays accuracy, confusion matrix, F1-score,\n",
    "    and one output image per class.\n",
    "\n",
    "    Args:\n",
    "        model: Trained PyTorch model.\n",
    "        test_loader: DataLoader for test set.\n",
    "        label_encoder: Label encoder to decode class names.\n",
    "        device: 'cuda' or 'cpu' where evaluation happens.\n",
    "    \"\"\"\n",
    "    model.to(device)  # Ensure model is on correct device\n",
    "    model.eval()  # Set to evaluation mode\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Model returns (output_image, output_class)\n",
    "            _, output_class = model(inputs)\n",
    "\n",
    "            # Get predicted class (argmax over logits)\n",
    "            preds = torch.argmax(output_class, dim=1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            y_true.extend(labels.cpu().tolist())  # Move to CPU for metrics\n",
    "            y_pred.extend(preds.cpu().tolist())\n",
    "\n",
    "    # Compute Accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Compute & Display Confusion Matrix\n",
    "    class_names = label_encoder.classes_  # Decode label names\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Normalize confusion matrix to percentages\n",
    "    cm_normalized = cm.astype(np.float32) / cm.sum(axis=1, keepdims=True) * 100\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(max(10, num_classes * 0.8), max(8, num_classes * 0.6)))  # Dynamic size\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=class_names)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".1f\", ax=ax)  # Use 1 decimal place for percentages\n",
    "\n",
    "    # Adjust x-axis label alignment and font sizes\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha=\"right\", va=\"top\", fontsize=max(8, 12 - num_classes // 5))\n",
    "    ax.set_yticklabels(class_names, rotation=0, fontsize=max(8, 12 - num_classes // 5))\n",
    "    ax.set_xlabel(\"Predicted Label\", fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel(\"True Label\", fontsize=12, labelpad=10)\n",
    "    ax.set_title(\"Confusion Matrix (Percentage)\", fontsize=14)\n",
    "\n",
    "    # Adjust layout with extra bottom margin for rotated labels\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2 + num_classes * 0.005)  # Dynamic bottom margin\n",
    "\n",
    "    plt.savefig(output_path + f\"{snr}_test_conf_matrix.png\")\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Epoch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_full_checkpoint(model, optimizer, scheduler=None, checkpoint_dir=\"models\", device=\"cuda\"):\n",
    "    checkpoint_files = glob.glob(os.path.join(checkpoint_dir, \"epoch_*.pth\"))\n",
    "    if not checkpoint_files:\n",
    "        raise FileNotFoundError(f\"No checkpoints found in {checkpoint_dir}\")\n",
    "\n",
    "    def extract_epoch(path):\n",
    "        match = re.search(r\"epoch_(\\d+)_\", os.path.basename(path))\n",
    "        return int(match.group(1)) if match else -1\n",
    "\n",
    "    checkpoint_files.sort(key=extract_epoch, reverse=True)\n",
    "    latest_checkpoint_path = checkpoint_files[0]\n",
    "\n",
    "    checkpoint = torch.load(latest_checkpoint_path, map_location=device)\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    if scheduler and checkpoint.get(\"scheduler_state_dict\") is not None:\n",
    "        scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "\n",
    "    if \"random_state\" in checkpoint:\n",
    "        torch.set_rng_state(checkpoint['random_state']['torch'])\n",
    "        np.random.set_state(checkpoint['random_state']['numpy'])\n",
    "        random.setstate(checkpoint['random_state']['python'])\n",
    "        if torch.cuda.is_available() and checkpoint['random_state']['cuda']:\n",
    "            torch.cuda.set_rng_state_all(checkpoint['random_state']['cuda'])\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    start_epoch = checkpoint.get(\"epoch\", 0) + 1\n",
    "    best_loss = checkpoint.get(\"loss\", float(\"inf\"))\n",
    "\n",
    "    print(f\"‚úÖ Loaded checkpoint from {latest_checkpoint_path} (Resuming from epoch {start_epoch})\")\n",
    "    return model, optimizer, scheduler, start_epoch, best_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_all_snrs(data_path, snr_range, mod_types, input_parameters, output_path):\n",
    "    all_X_train = []\n",
    "    all_y_train = []\n",
    "    all_Xy_test = {}\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for snr in snr_range:\n",
    "        input_data_folder = os.path.join(data_path, f\"snr_{snr}\")\n",
    "        print(f\"Loading {input_data_folder}\")\n",
    "        X, y = load_algorithm_snr_h5s(input_data_folder, mod_types)\n",
    "\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    "        )\n",
    "\n",
    "        all_X_train.append(X_train)\n",
    "        all_y_train.extend(y_train)\n",
    "        all_Xy_test[snr] = {\"X\": X_test, \"y\": y_test}\n",
    "\n",
    "    # Combine all training data\n",
    "    X_train = np.concatenate(all_X_train, axis=0)\n",
    "    y_train = np.array(all_y_train)\n",
    "\n",
    "    epoch_count = input_parameters[\"epoch_count\"]\n",
    "    learning_rate = input_parameters[\"learning_rate\"]\n",
    "    mds = \"ALL\" if len(mod_types) == 3 else mod_types[0]\n",
    "    snrs = \"ALL\" if len(snr_range) == 13 else f\"{snr_range[0]}_{snr_range[-1]}\"\n",
    "\n",
    "    output_data_folder = os.path.join(output_path, f\"snr_{snrs}_mds_{mds}_e{epoch_count}_lr{learning_rate}\\\\\")\n",
    "    os.makedirs(output_data_folder, exist_ok=True)\n",
    "\n",
    "    joblib.dump(label_encoder, os.path.join(output_data_folder, \"label_encoder.pkl\"))\n",
    "\n",
    "    train_loader = prepare_dataloader(X_train, y_train, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "    model = MainModel(num_classes=len(np.unique(y_train))).to(device)\n",
    "\n",
    "    # Use SSRLoss for LDC-Unet\n",
    "    criterion = SSRLoss(num_classes=len(np.unique(y_train)), feature_dim=256, lambda_reg=0.12).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=45, gamma=0.1)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        model, optimizer, scheduler, start_epoch, best_loss = load_full_checkpoint(\n",
    "            model,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            checkpoint_dir=output_data_folder,\n",
    "            device=device\n",
    "        )\n",
    "    except (FileNotFoundError, ValueError) as e:\n",
    "        print(f\"No valid checkpoint found. Starting fresh. {e}\")\n",
    "        start_epoch = 0\n",
    "        best_loss = float(\"inf\") \n",
    "\n",
    "    loss_history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        epochs=epoch_count,\n",
    "        patience=50,\n",
    "        output_model_dir=output_data_folder,\n",
    "        start_epoch=start_epoch\n",
    "    )\n",
    "\n",
    "    time_taken = time.time() - start_time\n",
    "\n",
    "    np.savetxt(os.path.join(output_data_folder, \"loss_history.csv\"), loss_history, delimiter=\",\")\n",
    "    plot_loss_curve(loss_history, output_data_folder)\n",
    "    display_confusion_matrix(model, train_loader, device, output_data_folder)\n",
    "\n",
    "    model_file_name = f\"model_snr_{snrs}_mds_{mds}_e{epoch_count}_lr{learning_rate}.pth\"\n",
    "    torch.save(model.state_dict(), os.path.join(output_data_folder, model_file_name))\n",
    "\n",
    "    for snr in snr_range:\n",
    "        test_loader = prepare_dataloader(\n",
    "            all_Xy_test[snr][\"X\"],\n",
    "            all_Xy_test[snr][\"y\"],\n",
    "            batch_size=64,\n",
    "        )\n",
    "\n",
    "        acc = evaluate_model(model, test_loader, label_encoder, device, output_data_folder, snr)\n",
    "\n",
    "        df_path = os.path.join(output_path, f\"{input_parameters['csv']}_results.csv\")\n",
    "        df = pd.read_csv(df_path)\n",
    "\n",
    "        new_row = {\n",
    "            \"Algorithm\": f\"LDC-Unet_{snrs}\",\n",
    "            \"SNR\": snr,\n",
    "            \"Modulations\": mds,\n",
    "            \"Accuracy (%)\": acc,\n",
    "            \"Time Taken (Minutes)\": time_taken,\n",
    "            \"Learning Rate\": learning_rate,\n",
    "            \"Epoch Count\": f\"{len(loss_history)} / {epoch_count}\",\n",
    "        }\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        df.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:\\\\Apps\\\\Code\\\\aimc-spec-7\\\\preprocessed_images\\\\ldc\\\\\"\n",
    "output_path = \"C:\\\\Apps\\\\Code\\\\LDC_Unet\\\\\"\n",
    "\n",
    "snr_range = [10, 5, 0, -2, -4, -6, -8, -10, -12, -14, -16, -18, -20]\n",
    "\n",
    "modulation_types = [\n",
    "    \"FM\",\n",
    "    # \"PM\",\n",
    "    # \"HYBRID\",\n",
    "]\n",
    "\n",
    "input_parameters = {\n",
    "    \"epoch_count\": 1,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"csv\": \"ldc\",\n",
    "}\n",
    "\n",
    "train_on_all_snrs(data_path, snr_range, modulation_types, input_parameters, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
